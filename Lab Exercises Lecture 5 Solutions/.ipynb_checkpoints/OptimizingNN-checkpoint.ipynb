{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Neural Network Hyperparameters\n",
    "\n",
    "We will consider again an Image Recognition problem with the MNIST dataset (Images of 28 x 28 pixels). \n",
    "The MNIST dataset has a training set of 60,000 images and a test set of 10,000 images. \n",
    "The digits have been sized-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "In this Notebook you will follow three different approaches to tune the hyperparameters:\n",
    "- \"Trial and Error\" approach\n",
    "- \"Grid Search\" Hyperparameter optimization with Scikit-Learn wrapper\n",
    "- \"Random Search\" Hyperparameter optimization with Scikit-Learn wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() # train_x, train_y, test_x, test_y\n",
    "# x values are the 28x28 pixels\n",
    "# y values are the labels, the digit that is being represented in the image. We have 10 labels. Digits from 0 to 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to encode the categorical labels in one-hot format\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the training set into training and validation set\n",
    "# 30% validation, 70% training\n",
    "\n",
    "split_size = int(train_images.shape[0]*0.7)\n",
    "\n",
    "train_images, val_images = train_images[:split_size], train_images[split_size:]\n",
    "train_labels, val_labels = train_labels[:split_size], train_labels[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "seed = 42\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "\n",
    "Build a neural network with 3 layers, input, hidden and output:\n",
    "- Dense layer with 50 hidden units and an appropriate activation function;\n",
    "- Dense layer with 10 output units and appropriate activation function;\n",
    "\n",
    "First we define some useful parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_num_units = 784 # 28x28\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Keras packages that you think may need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the model as described above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the model with an optimizer and an appropriate loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model (also with the validation set).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model: get predictions and evaluate the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve it by tuning some Hyperparameters.\n",
    "\n",
    "### Hyperparameters Optimization - Trial and Error\n",
    "\n",
    "Some important parameters to look out while optimizing neural networks are:\n",
    "- Type of architecture\n",
    "- Number of layers\n",
    "- Number of neurons per layer\n",
    "- Regularization parameters\n",
    "- Learning rate\n",
    "- Type of optimization/backpropagation technique\n",
    "- Dropout rate\n",
    "- Weight sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat all the previous steps (train, test etc..) but tuning the following parameters:\n",
    "1. Make the model \"wide\": Increase the number of neurons in the hidden layer; \n",
    "2. Make the model \"deep\": Increase the number of hidden layers neurons each;\n",
    "3. Dropout to deal with Overfitting;\n",
    "4. Increase Epochs to 50;\n",
    "5. Both \"wide\" and \"deep\": more hidden layers, each with more than 50 neurons\n",
    "\n",
    "After every step, analyse your results and draw some conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make the model \"wide\": increase number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the new variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations: what can you notice from these results? Is your model performing better than before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**: the model should perform significantly better than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make the model \"deep\": Increase the number of hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the new variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations: what can you notice from these results? Is your model performing better than before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the new variables, remember to define also the dropout_ratio.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "dropout_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations: what can you notice from these results? Is your model improving?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Increase training Epochs to 50.\n",
    "\n",
    "This will take a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the new variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations: what can you notice from these results? Has the accuracy increased?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make the model \"wide\" and \"deep\": more hidden layers, each with more than 50 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the new variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network. Use 25 epochs if 50 takes too long.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations: what do you think about your final model?\n",
    "It seems that we obtained our final solution model. Let's evaluate it with some predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**: Finally we get our very good model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make some predictions and Evaluate the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Optimization - Grid Search\n",
    "\n",
    "Instead of proceeding with a \"trial and error\" approach we can also use GridSearch to combine all the hyperparameters we want to tune. The Grid search works by trying every possible combination of parameters you want to try, therefore it will take a lot of time to perform the entire search.\n",
    "\n",
    "What you have to do is to use Sequential() model in Keras as a part of the Scikit-Learn workflow via the wrappers. \n",
    "Check out how this [workflow](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV) works.\n",
    "\n",
    "\n",
    "Please note that without GPU is extremely time consuming to tune all the hyperparameters in one shoot, by using an appropriate number of epochs. For this reason, in this example the idea is for you to understand how you can use GridSerach with Keras Model, but you will probably not be able to obtain an excellent model.\n",
    "\n",
    "For this reason, try to tune the number of neurons in the hidden layers (more than one hidden layer) with just 5-10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import GridSearchCV and KerasClassifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 784\n",
    "output_num_units = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a function called `create_model` in which you build your KerasClassifier with number of hidden units equal to a general variable (you can call this `neurons`). Inside the function you should then also compile the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a model wrapper.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary of parameters grid for the number of neurons in the hidden layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search: use `GridSearchCV`with the model you have obtained from the wrapper as estimator and the dictionary you have just created as param_grid.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the result from the Grid Search, call your result `grid_result`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's print some results. Fill in the #TO DOs with the best_score and best_params that you got after fitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (#TO DO: take the best score, #TO DO: take the best parameters))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Optimization - Random Search\n",
    "\n",
    "Similarly, we can use Scikit-Learn workflow to perform [random search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import RandomizedSearchCV.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Search: use `RandomizedSearchCV` with the model you have obtained from the wrapper as estimator and the dictionary you have created for GridSearch as param_distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the result from the Randomized Search, call your result `random_result`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's print some results. Fill in the #TO DOs with the best_score and best_params that you got after fitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (#TO DO: take the best score, #TO DO: take the best parameters))\n",
    "means = random_result.cv_results_['mean_test_score']\n",
    "stds = random_result.cv_results_['std_test_score']\n",
    "params = random_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Optimization - Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual tuning (Trial and Error), grid search and random search are considered brute-force methods. \n",
    "Grid search is an exhaustive approach to evaluate the hyperparameter values defined in a grid. \n",
    "The random search approach will randomly choose the values for the hyperparameters. Grid and\n",
    "random search perform better than manual tuning, but they do not consider past evaluations.\n",
    "Hence, they lose significant time evaluating hyperparameters in the same inadequate region.\n",
    "Furthermore, the objective functions to minimize are computationally expensive and running\n",
    "them each time with a new set of parameters is time-demanding. \n",
    "Therefore, Bergstra et al. proposed a model-based method called Sequential Model-Based Optimization (SMBO).\n",
    "The main idea of this approach is to create a surrogate model of the objective function using a\n",
    "probabilistic distribution. This surrogate model bases on the Bayesâ€™ theorem. At each new iteration, the surrogate will become more and more confident about which new guess can lead to improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use the package [hyperas](https://github.com/maxpumperla/hyperas)\n",
    "\n",
    "````pip install hyperas````\n",
    "\n",
    "To do hyper-parameter optimization on a model, we just wrap the parameters we want to optimize into double curly brackets and choose a distribution. \n",
    "\n",
    "**Define the create model function again, but returning not only the model but the function to minimize and the status. Complete the TO DO lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperas.distributions import choice\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe \n",
    "\n",
    "# Function to create model\n",
    "def create_model():\n",
    "  \n",
    "    model = models.Sequential()  \n",
    "    # Notice here how we define the number of neurons per layer\n",
    "    model.add(layers.Dense(units={{choice([50, 100, 250, 500])}}, input_shape=(28*28,), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units={{choice([50, 100, 250, 500])}}, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units={{choice([50, 100, 250, 500])}}, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units={{choice([50, 100, 250, 500])}}, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units={{choice([50, 100, 250, 500])}}, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    # model_compile\n",
    "    model.compile(#TO DO)\n",
    "    \n",
    "        # model fitting\n",
    "    model.fit(#TO DO)\n",
    "\n",
    "    score = model.evaluate(#TO DO)\n",
    "    accuracy = score[1]\n",
    "    return {'loss': -accuracy,'status': STATUS_OK, 'model': model} # We want to minimize the -accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data for the optimizer should be returned from a function ````get_data````**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "    train_images = train_images.reshape((60000, 28 * 28))\n",
    "    train_images = train_images.astype('float32') / 255\n",
    "\n",
    "    test_images = test_images.reshape((10000, 28 * 28))\n",
    "    test_images = test_images.astype('float32') / 255\n",
    "    # We need to encode the categorical labels in one-hot format\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The last step is to run the optimization, which is done as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=get_data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='OptimizingNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's print some results. Complete the TO DO lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate( #TODO, #TODO))\n",
    "\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
