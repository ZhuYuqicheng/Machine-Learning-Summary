{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we will try to get a general overview of CNNs and what can be done with them.\n",
    "We will use the MNIST dataset.\n",
    "At the end of the notebook as an extra side, you can also try to implement something similar by loading the CIFAR-10 dataset.\n",
    "\n",
    "Please note that this notebook is not an advanced implementation of CNNs. It is just for you to learn ho to implement from scratch a simple CNN, without using any pre-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "The MNIST dataset is a large database of handwritten digits. It contains 60,000 training images and 10,000 testing images.\n",
    "(We already know this Dataset from previous labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the packages that you may need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10, mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import MaxPooling2D, Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "#from seansUtils.research import StatsCallback, ModelSummary\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "%matplotlib inline\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the MNIST dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform some data pre-processing on both input and labels. Hint: reshape the input with dimension (28,28,1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the shape of the data and some sample to visualize them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Data\n",
    "print('--- THE DATA ---')\n",
    "print('train_images shape:', train_images.shape)\n",
    "print(train_images.shape[0], 'train samples')\n",
    "print(test_images.shape[0], 'test samples')\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN\n",
    "\n",
    "This is the most basic CNN: you will have to build a convolutional neural network that is composed by 2 Convolutional layers ([Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/)) and 2 Fully Connected layers (Dense). \n",
    "\n",
    "Tipps:\n",
    "\n",
    "- Remember the first layer always needs the input shape in this case input_shape=(28, 28, 1).\n",
    "- Use proper activation functions.  \n",
    "- Choose number of neurons of last layer accordingly to the number of classes\n",
    "- Choose the loss function and last layer activation function according to the task. In this case, classification\n",
    "- To connect convolutional layers with dense layers you always we need to flatten the vectors. Use [Flatten layer](https://keras.io/api/layers/reshaping_layers/flatten/).\n",
    "\n",
    "**Our desired architecture**:\n",
    "- Convolutional layer: 32 filters, 3x3;\n",
    "- ReLU activation function;\n",
    "- Convolutional layer: 32 filters, 3x3;\n",
    "- ReLU activation function;\n",
    "- Flatten;\n",
    "- Fully Connected layer of size 128;\n",
    "- ReLU activation function;\n",
    "- Fully Connected layer of size 10;\n",
    "- Softmax activation function;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the number of batches and epochs. Without GPU please keep number of epochs under 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Vanilla CNN model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model_vanilla.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model_vanilla.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla.add(Flatten())\n",
    "model_vanilla.add(Dense(units=128))\n",
    "model_vanilla.add(Activation('relu'))\n",
    "\n",
    "# Prediction output Layer\n",
    "model_vanilla.add(Dense(units=10))\n",
    "model_vanilla.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a summary of the model.**\n",
    "\n",
    "*Note*: It is important to understand how Keras calculate the different Output shapes and number of parameters. Please see the lecture for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What happens if you use a Conv2D layer with kernel size =(1,1)?*\n",
    "Run some experiments and check the model summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the model with an optimizer and a loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Max Pooling and Dropout\n",
    "\n",
    "Let's implement the same CNN as above but plus Max Pooling and Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the new network with max pooling and dropout. You should think a little bit where Max Pooling and Dropout should be inserted. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model_vanilla_pooling.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model_vanilla_pooling.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model_vanilla_pooling.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model_vanilla_pooling.add(Dropout(rate=0.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model_vanilla_pooling.add(Flatten())\n",
    "model_vanilla_pooling.add(Dense(units=128))\n",
    "model_vanilla_pooling.add(Activation('relu'))\n",
    "    \n",
    "# More Dropout\n",
    "model_vanilla_pooling.add(Dropout(rate=0.5))\n",
    "\n",
    "# Fully Connected Layer for Prediction\n",
    "model_vanilla_pooling.add(Dense(units=10))\n",
    "model_vanilla_pooling.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a summary of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla_pooling.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_vanilla_pooling.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the test accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: More complex CNN with CIFAR-10\n",
    "\n",
    "As an extra part, you can also load the CIFAR-10 dataset, perform a similar data pre-processing as the MNIST dataset and implement a proper CNN. In this case, the dataset consists of 60,000 32x32 color images (RGB i.e. depth is 3) in 10 classes, with 6,000 images per class. Therefore you will need a network that is a little bit deeper, with 4 convolution layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "#load the dataset\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "\n",
    "# print shape \n",
    "print(\"train image shape:\",x_train.shape)  \n",
    "print(\"train label shape:\",y_train.shape)  \n",
    "print(\"test image shape:\",x_test.shape) \n",
    "print(\"test label shape:\",y_test.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot some images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "fig, axes = plt.subplots(3, 3, figsize=(8,8))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        ax.imshow(x_train[i])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "\n",
    "# divide by max value 255\n",
    "x_train=x_train/225\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cifar-10 dataset the label contains integer values ranging from 0 to 9 each representing a unique class:\n",
    "\n",
    "0: airplane\n",
    "1: automobile\n",
    "2: bird\n",
    "3: cat\n",
    "4: deer\n",
    "5: dog\n",
    "6: frog\n",
    "7: horse\n",
    "8: ship\n",
    "9: truck\n",
    "    \n",
    "Use one-hot enconding format for the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "print(\"First label before one-hot encondig: \", y_train[0])\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,10)\n",
    "y_test=np_utils.to_categorical(y_test,10)\n",
    "\n",
    "print(\"First label after one-hot encondig: \", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the CNN model**\n",
    "\n",
    "These parts are not guided as the previous one, it's up to you to start from scratch and try out the implementation. However the procedure is pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get summary of the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we know different types of layers: Input, Dense, Conv2D, Dropout, Pooling, Activations. See information of those and more available layers [here](https://keras.io/api/layers/). Different configurations of those layers compose different structures seen during the lecture: GoogLeNet, AlexNet, VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
